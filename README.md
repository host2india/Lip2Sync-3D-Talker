# Lip2Sync-3D-Talker
ğŸš€ Lip2Sync-3D-Talker
High-precision 3D Talking-Head Generator using SadTalker + Lip2Sync Engine

Lip2Sync-3D-Talker is a production-ready talking-head engine that integrates:

âœ… SadTalker 3D Pipeline
âœ… Full BFM 3DMM support
âœ… Audio-driven facial animation (expression + pose)
âœ… GFPGAN face enhancement
âœ… RealESRGAN background upscaling
âœ… FastAPI-ready engine.py
âœ… GPU/CPU auto-switching

Built and optimized by Captain & Balu for high-quality lip-synced 3D avatar generation.

ğŸ“Œ Features
ğŸ­ 3D Face Reconstruction

Uses BFM_Fitting for accurate 3D mesh.

ğŸ—£ï¸ Audio-Driven Expressions

audio2exp + audio2pose pipeline.

ğŸ”¥ Rendering Engine

FaceVid2Vid + Sparse Motion + Mapping networks.

âœ¨ Enhancement Pipeline

GFPGAN for face clarity

RealESRGAN for background

ğŸ§  Smart Engine

Detects GPU

Falls back to CPU

Creates temp folders

Auto-detects checkpoints

Supports full SadTalker CLI

ğŸ“ Repo Structure
Lip2Sync-3D-Talker/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ engines/
â”‚       â””â”€â”€ sadtalker/
â”‚           â”œâ”€â”€ engine.py          â† Main engine
â”‚           â”œâ”€â”€ utils.py
â”‚           â”œâ”€â”€ config.yaml
â”‚           â””â”€â”€ output/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ sadtalker/
â”‚       â””â”€â”€ checkpoints/           â† Place model files here
â”‚
â”œâ”€â”€ requests/                      â† API examples
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ“¥ Model Checkpoints Required
Purpose	File
Audioâ†’Expression	audo2exp_00300-model.pth
Audioâ†’Pose	audio2pose_00140-model.pth
Mapping Network	mapping_00109-model.pth.tar
Face Renderer	epoch_00190.pth.tar
3D Reconstruction	epoch_20.pth
Hubert Soft	hubert_soft.pt
GFPGAN	GFV.pth
Morphable Model	BFM_Fitting/â€¦ folder
(Optional) 68 Landmarks	shape_predictor_68_face_landmarks.dat
(Optional) FaceVid2Vid	facevid2vid_00189-model.pth.tar

ğŸ“Œ Place all inside:

models/sadtalker/checkpoints/

âš¡ Installation (Local System)
1ï¸âƒ£ Clone the Repo
git clone https://github.com/host2india/Lip2Sync-3D-Talker.git
cd Lip2Sync-3D-Talker

2ï¸âƒ£ Install Requirements
pip install -r requirements.txt

3ï¸âƒ£ Place models in:
models/sadtalker/checkpoints/

â–¶ï¸ Run the Engine

Test locally:

from app.engines.sadtalker.engine import SadTalkerEngine

engine = SadTalkerEngine()

out = engine.infer_from_files(
    "image.png",
    "audio.wav"
)

print("Generated Video:", out)


Output will appear here:

app/engines/sadtalker/output/

âš¡ Run on Google Colab (GPU)

ğŸš€ 5Ã—â€“20Ã— faster than CPU.

!git clone https://github.com/host2india/Lip2Sync-3D-Talker.git
%cd Lip2Sync-3D-Talker

# Auto installer script (Captain will generate next)


Captain will generate the Colab Auto Setup Script after this README.

ğŸ§ª API Example (FastAPI)
from fastapi import FastAPI, UploadFile
from app.engines.sadtalker.engine import SadTalkerEngine

app = FastAPI()
engine = SadTalkerEngine()

@app.post("/talk")
async def talk(image: UploadFile, audio: UploadFile):
    path = await engine.infer_from_uploads(image, audio)
    return {"video": path}

ğŸ”¥ Why this Repo is Better than Original SadTalker

Pure Python engine (no shell hacks)

Cleaner inference flow

GPU/CPU auto-detection

Handles all 3DMM and face enhancement flags

Battle-tested by Captain for Linux / Colab / RunPod

Fully production-ready for API servers

Organized Lip2Sync-style engine architecture

ğŸ“ License

MIT License â€” free to modify and use commercially.

â¤ï¸ Credits

SadTalker (Original Research)

GFPGAN / RealESRGAN Authors

Lip2Sync (host2india)

Captain (AI Integration Guidance)

Balu (Implementation & Testing)
